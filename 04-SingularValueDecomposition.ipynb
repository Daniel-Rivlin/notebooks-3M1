{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singular value decompostion of a real-valued $m \\times n$ matrix $\\boldsymbol{A}$ is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\boldsymbol{U}$ is an $m \\times m$ orthogonal matrix;\n",
    "- $\\boldsymbol{\\Sigma}$ is an $m \\times n$ diagonal matrix with diagonal entries $\\sigma_{1} \\ge  \\sigma_{2} \\ge \\ldots \\ge \\sigma_{p} \\ge 0$, where $p = \\min(m, n)$; and\n",
    "- $\\boldsymbol{U}$ is an $n \\times n$ orthogonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use NumPy to compute the SVD and Matplotlib to visualise results, so we first import some modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you run this notebook yourself it can take sometime because it computes number of moderate size SVD problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low rank approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we can represent a matrix as a sum of rank-1 matrices:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\sum_{i} \\sigma_{i} \\boldsymbol{u}_{i} \\boldsymbol{v}^{T}_{i}\n",
    "$$\n",
    "\n",
    "where $\\sigma_{i}$ is the $i$th singular value and $\\boldsymbol{u}_{i}$ and $\\boldsymbol{v}_{i}$ are the $i$th columns vectors of $\\boldsymbol{U}$ and $\\boldsymbol{V}$, respectively from the SVD. Clearly, for any $\\sigma_{i} = 0$ we can avoid storing the data that makes no contribution. If $\\sigma_{i}$ is small, then the contribution of $\\boldsymbol{u}_{i} \\boldsymbol{v}^{T}_{i}$ is small and we discard it and introduce only a small 'error' to the matrix. We will use low rank approximations in a number of examples in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a $100 \\times 200$ matrix that has entries equal to one or zero. We create a matrix with all entries set to zero, and we then set some entries equal to one in the pattern of rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones((100, 200))\n",
    "A[33:33 + 4, 33:133] = 0.0\n",
    "A[78:78 + 4, 33:133] = 0.0\n",
    "A[33:78+4, 33:33+4] = 0.0\n",
    "A[33:78+4, 129:129+4] = 0.0\n",
    "plt.imshow(A, cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the SVD and counting the number of singular values that are greater than $10^{-9}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(A, full_matrices=False)\n",
    "print(\"Number of singular values greater than 1.0e-9: {}\".format((s > 1.0e-9).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only three nonzero singular values, we could reconstruct the matrix with very little data - just three singular values and six vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the same matrix problem again, this time with some back ground noise in the white regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones((100, 200))\n",
    "A = A - 1.0e-1*np.random.rand(100, 200)\n",
    "A[33:33 + 4, 33:133] = 0.0\n",
    "A[78:78 + 4, 33:133] = 0.0\n",
    "A[33:78+4, 33:33+4] = 0.0\n",
    "A[33:78+4, 129:129+4] = 0.0\n",
    "plt.imshow(A, cmap='gray', interpolation='none');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of the noise is clear in the image.\n",
    "\n",
    "We can try to eliminate much of the background noise via a low-rank approximation of the noisy image that discards information associated with small singular values of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SVD of nois matrix\n",
    "U, s, V = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "# Set any singular values less than 1.0 equation zero\n",
    "s[s < 1.0] = 0.0\n",
    "\n",
    "# Reconstruct low rank approximation and display\n",
    "A_denoised = np.dot(U, np.dot(np.diag(s), V))\n",
    "plt.imshow(A_denoised, cmap='gray', interpolation='none')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that much of the noise in the image has been eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray scale image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a colour PNG file. It uses three colour channels (red/green/blue), with at each pixel an 8-bit unsigned integer (in the range $[0, 255]$, but sometimes represented as a float) for each colour for the colour intensity. This is know as 24-bit colour - three channels times 8 bit.\n",
    "\n",
    "We load the image as three matrices (red, green, blue), each with dimension equal to the number pixels in each direction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"https://github.com/garth-wells/notebooks-3M1/raw/master/photo/2020-1.png\"\n",
    "img_colour = Image.open(urlopen(url))\n",
    "img_colour = img_colour.convert('RGB')\n",
    "\n",
    "print(\"Image size (pixels):\", img_colour.size)\n",
    "print(\"Image array shape:  \", np.array(img_colour).shape)\n",
    "\n",
    "plt.figure(figsize=(15, 15/1.77))\n",
    "plt.imshow(img_colour);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could work with the colour image, but it is simpler to work with a gray scale image because then we have only one value for the colour intensity at each pixel rather than three (red/green/blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bw = img_colour.convert('L')\n",
    "\n",
    "plt.figure(figsize=(15, 15/1.77))\n",
    "plt.imshow(img_bw, cmap='gray');      \n",
    "print(\"Image array shape: {}\".format(img_bw.size))\n",
    "\n",
    "plt.savefig(\"bw.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the image to a regular matrix with values between 0 and 255, with each entry corresponding to a pixel in the image. Creating the matrix and inspecting first four rows and three columns (top left corner of the image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array(img_bw)\n",
    "print(\"Image shape:\", img_array.shape)\n",
    "print(img_array[:4, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, maybe we can discard information associated with small singular values without perceiving any visual change in the image. To explore this, we compute the SVD of the gray scale image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(img_array, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `full_matrices=False` tells NumPy to not store all the redundant zero terms in the $\\boldsymbol{\\Sigma}$ array. This is the normal approach in practice, but not in most text books. Note that NumPy return the singular values as a one-dimendional array, not as a matrix.\n",
    "\n",
    "We now print the largest and smallest singular values, and plot all the singular values $\\sigma_{i}$ on a log-scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of singular values: {}\".format(len(s)))\n",
    "print(\"Max, min singular values: {}, {}\".format(s[0], s[-1]))\n",
    "\n",
    "plt.xlabel('$i$')\n",
    "plt.ylabel('$\\sigma_i$')\n",
    "plt.title('Singular values')\n",
    "plt.yscale('log')\n",
    "plt.plot(s, 'bo');\n",
    "\n",
    "plt.savefig(\"bw-svd.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try compressing the image. We first try retaining using only the largest 25% of values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute num_sigma/4 (25%) and zero values \n",
    "r = int(0.25*len(s)) \n",
    "\n",
    "# Re-construct low rank approximation (this may look a little cryptic, but we use the below \n",
    "# expression to avoid unecessary computation)\n",
    "compressed = U[:,:r].dot(s[:r, np.newaxis]*V[:r,:])\n",
    "compressed = compressed.astype(int)\n",
    "\n",
    "# Plot compressed and original image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 18/1.77));\n",
    "axes[0].set_title('Compressed image with largest 25% of singular values retained')\n",
    "axes[0].imshow(compressed, cmap='gray');\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_array, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have discarded 3/4 of the singular values, but can  barely perceive a difference in the image.\n",
    "\n",
    "To explore other levels of compression, we write a function that takes the fraction of singular values we wish to retain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_image(U, s, V, f):\n",
    "    \"Compress image where 0 < f <= 1 is the fraction on singular values to retain\"\n",
    "    r = int(f*len(s))\n",
    "    return (U[:,:r].dot(s[:r, np.newaxis]*V[:r,:])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try retaining just 10% of the singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress image/matrix\n",
    "compressed = compress_image(U, s, V, 0.1)\n",
    "\n",
    "# Plot compressed and original image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "axes[0].set_title('Compressed image with largest 10% of singular values retained')\n",
    "axes[0].imshow(compressed, cmap='gray');\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_array, cmap='gray');\n",
    "\n",
    "plt.savefig(\"bw-0-10.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with only 10% if the singular values retains, it is hard to perceive a difference between the images. Next we try keeping only 2%: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress image/matrix\n",
    "compressed = compress_image(U, s, V, 0.02)\n",
    "\n",
    "# Plot compressed and original image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "axes[0].set_title('Compressed image with largest 2% of singular values retained')\n",
    "axes[0].imshow(compressed, cmap='gray');\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_array, cmap='gray');\n",
    "\n",
    "plt.savefig(\"bw-0-02.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see some image clear degradation, but the image is sill recognisable. We'll try one more case where we retain only 0.5% of the singular values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress image/matrix\n",
    "compressed = compress_image(U, s, V, 0.005)\n",
    "\n",
    "# Plot compressed and original image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "axes[0].set_title('Compressed image with largest 0.5% of singular values retained')\n",
    "axes[0].imshow(compressed, cmap='gray');\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_array, cmap='gray');\n",
    "\n",
    "plt.savefig(\"bw-0-005.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image quality is now quite poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour image: RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now try compressing a colour image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image array shape: {}\".format(img_colour.size))\n",
    "\n",
    "plt.figure(figsize=(20,20/1.77))\n",
    "plt.title('This is a photo of 2020 3M1 class members')\n",
    "plt.imshow(img_colour);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the red, green and blue components to have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display red, green and blue channels by zeroing other channels\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 20/1.77))\n",
    "img_array = np.array(img_colour)\n",
    "\n",
    "# Zero the g/b channels\n",
    "red = img_array.copy()\n",
    "red[:,:,(1,2)] = 0.0\n",
    "axes[0].imshow(red);\n",
    "\n",
    "# Zero the r/b channels\n",
    "green = img_array.copy()\n",
    "green[:,:,(0,2)] = 0.0\n",
    "axes[1].imshow(green);\n",
    "\n",
    "# Zero the r/g channels\n",
    "blue = img_array.copy()\n",
    "blue[:,:,(0,1)] = 0.0\n",
    "axes[2].imshow(blue);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute an SVD for the matrix of each colour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SVD for each colour\n",
    "U, s, V = [0]*3, [0]*3, [0]*3\n",
    "for i in range(3):\n",
    "    U[i], s[i], V[i] = np.linalg.svd(img_array[:, :, i], full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressing the matrix for each colouring separately and then reconstructing the three-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress each colour separately\n",
    "compressed = [compress_image(U[i], s[i], V[i], 0.1) for i in range(3)]\n",
    "\n",
    "# Reconstruct 3D RGB array and filter any values outside of (0, 1)\n",
    "compressed = np.dstack(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the compressed and original images side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "axes[0].set_title('Image with largest 10% of singular values retained')\n",
    "axes[0].imshow(compressed, interpolation=\"nearest\");\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_colour);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retaining 10% of the singular values for each colour, we can see some artifacts in the compressed image, which indicates that using the SVD for each colour independently is probably not a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour image: YCbCr\n",
    "\n",
    "A better approach is to split the image into [YCbCr](https://en.wikipedia.org/wiki/YCbCr), rather than RGB.\n",
    "YCbCr is splits the image into luminance (Y), and chrominance (Cb and Cr) colour values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_colour_ycbcr = np.array(img_colour.convert(\"YCbCr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Luminance(Y), Blue Chroma(Cb) and Red Chroma(Cr) channels\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 20/1.77))\n",
    "\n",
    "Y = img_colour_ycbcr[:,:,0]\n",
    "axes[0].imshow(Y, cmap='gray');\n",
    "\n",
    "Cb = img_colour_ycbcr[:,:,1]\n",
    "axes[1].imshow(Cb, cmap='gray');\n",
    "\n",
    "Cr = img_colour_ycbcr[:,:,2]\n",
    "axes[2].imshow(Cr, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the SVD of each channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SVD for each channel\n",
    "U, s, V = [0]*3, [0]*3, [0]*3\n",
    "for i in range(3):\n",
    "    U[i], s[i], V[i] = np.linalg.svd(img_colour_ycbcr[:, :, i], full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress each channel, and display compressed channels in gray scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress each component separately\n",
    "compressed = [compress_image(U[0], s[0], V[0], 0.05),\n",
    "              compress_image(U[1], s[1], V[1], 0.005),\n",
    "              compress_image(U[2], s[2], V[2], 0.005)]\n",
    "# Reconstruct 3D YCbCr array\n",
    "compressed = np.dstack(compressed)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 20/1.77))\n",
    "Y = compressed[:,:,0]\n",
    "axes[0].imshow(Y, cmap='gray');\n",
    "\n",
    "Cb = compressed[:,:,1]\n",
    "axes[1].imshow(Cb, cmap='gray');\n",
    "\n",
    "Cr = compressed[:,:,2]\n",
    "axes[2].imshow(Cr, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine compressed channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "axes[0].set_title('Image with largest 20% of brightness singular values retained and 0.5% colours')\n",
    "im = Image.fromarray(np.uint8(compressed), mode=\"YCbCr\")\n",
    "axes[0].imshow(im)\n",
    "axes[1].set_title('Original image')\n",
    "axes[1].imshow(img_colour);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive compression\n",
    "\n",
    "We'll now create an interactive image with sliders to interactively control the compression level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "img = Image.open('./photo/IMG_20190117_141222563.png')\n",
    "\n",
    "img_colour_ycbcr = np.array(img.convert(\"YCbCr\"))\n",
    "\n",
    "# Compute SVD for each channel\n",
    "U0, s0, V0 = [0]*3, [0]*3, [0]*3\n",
    "for i in range(3):\n",
    "    U0[i], s0[i], V0[i] = np.linalg.svd(img_colour_ycbcr[:, :, i], full_matrices=False)\n",
    "\n",
    "@interact(ratio_Y=(0.005, 0.4, 0.02), \n",
    "          ratio_Cb=(0.001, 0.1, 0.01), \n",
    "          ratio_Cr=(0.001, 0.1, 0.01))\n",
    "def plot_image(ratio_Y=0.1, ratio_Cb=0.01, ratio_Cr=0.01):\n",
    "\n",
    "    compressed = [compress_image(U0[0], s0[0], V0[0], ratio_Y),\n",
    "                  compress_image(U0[1], s0[1], V0[1], ratio_Cb),\n",
    "                  compress_image(U0[2], s0[2], V0[2], ratio_Cr)]\n",
    "\n",
    "    # Reconstruct 3D YCbCr array\n",
    "    compressed = np.dstack(compressed)    \n",
    "    img_compressed = Image.fromarray(np.uint8(compressed), mode=\"YCbCr\")\n",
    "\n",
    "    # Show\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 20/1.77))\n",
    "\n",
    "    axes[0].set_title('Compressed image')\n",
    "    axes[0].imshow(img_compressed)\n",
    "\n",
    "    axes[1].set_title('Original image')\n",
    "    axes[1].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the rank of a matrix is not a binary question in the context of floating point arithmetic or measurement errors. The SVD can be used to determine the 'effective rank' of a matrix. \n",
    "\n",
    "Consider the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 1], [2, 2, 2], [1, 0 ,1]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the first two rows are linearly dependent and the rank of this matrix is 2. We can verify this using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rank of A is: {}\".format(np.linalg.matrix_rank(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add some noise in the range $(0, 10^{-6})$ to the matrix entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "A = A + 1.0e-6*np.random.rand(A.shape[0], A.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rank of A (with noise) is: {}\".format(np.linalg.matrix_rank(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that we have a 'data set' that is linearly dependent, but this is being masked by very small measurement noise. \n",
    "\n",
    "Computing the SVD of the matrix with noise and printing the singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(A)\n",
    "print(\"The singular values of A (with noise) are: {}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we define the effective rank as the number of singular values that are greater than the noise level, the effective rank of $\\boldsymbol{A}$ is 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank deficient least-squares problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For least squares problem, we have seen before that we solve\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}^{T} \\boldsymbol{A} \\hat{\\boldsymbol{x}} = \\boldsymbol{A}^{T} \\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\boldsymbol{x}} &= (\\boldsymbol{A}^{T} \\boldsymbol{A})^{-1} \\boldsymbol{A}^{T} \\boldsymbol{b}\n",
    "\\\\\n",
    "&= \\boldsymbol{A}^{+}\\boldsymbol{b}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Everything is fine as long as $\\boldsymbol{A}$ is full rank. The problem is that we might have data that leads to $\\boldsymbol{A}$ not being full rank. For example, if we try to fit a polynomial in $x$ and $y$, but the data lies on a line. \n",
    "\n",
    "We have covered in the lectures how to handle least-squares problems that are rank deficient. Here we present an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: fitting points in a two-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we are given four data points that depend on $x$ and $y$, and we are asked to fit a polynomial of the form\n",
    "\n",
    "$$\n",
    "f(x, y) = c_{00} + c_{10}x + c_{01}y + c_{11}xy\n",
    "$$\n",
    "\n",
    "to the data points. Normally, we would expect to be able to fit the above polynomial to four data points by interpolation, i.e. solving $\\boldsymbol{A} \\boldsymbol{c} = \\boldsymbol{f}$ where\n",
    "$\\boldsymbol{A}$ a square Vandermonde matrix. However, if the points happened to lie on a line, then $\\boldsymbol{A}$ will be singular. If the points happen to almost lie on a line, then $\\boldsymbol{A}$ will be close to singular. \n",
    "\n",
    "A possibility is to exclude zero or small singular values from the process, thereby finding a least-squares fit with minimal $\\|\\boldsymbol{c}\\|_{2}$. We test this for the data set \n",
    "\n",
    "\\begin{equation}\n",
    "f_{1}(1, 0) = 3, \\\\\n",
    "f_{2}(2, 0) = 5, \\\\\n",
    "f_{3}(3, 0) = 7, \\\\\n",
    "f_{4}(4, 0) = 9.\n",
    "\\end{equation}\n",
    "\n",
    "The data lies on the line $y = 0$, and is in fact is linear in $x$.\n",
    "\n",
    "We create arrays to hold this data, and visualise the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, f = np.zeros(4), np.zeros(4), np.zeros(4)\n",
    "x[0], y[0], f[0] = 1.0, 0.0, 3.0\n",
    "x[1], y[1], f[1] = 2.0, 0.0, 5.0\n",
    "x[2], y[2], f[2] = 3.0, 0.0, 7.0\n",
    "x[3], y[3], f[3] = 4.0, 0.0, 9.0\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f')\n",
    "ax.scatter(x, y, f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the polynomial coefficients we want to solve\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "1 & x_{1} & y_{1} & x_{1}y_{1}  \\\\  \n",
    "1 & x_{2} & y_{2} & x_{2}y_{2}  \\\\  \n",
    "1 & x_{3} & y_{3} & x_{3}y_{3}  \\\\  \n",
    "1 & x_{4} & y_{4} & x_{4}y_{4}  \\\\  \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "c_{00} \\\\ c_{10} \\\\ c_{01} \\\\ c_{11}  \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "f_{1} \\\\ f_{2} \\\\ f_{3} \\\\ f_{4}  \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where the matrix is the Vandermonde matrix. We can use a NumPy function to create the Vandermonde matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.polynomial.polynomial.polyvander2d(y, x, [1, 1])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear by inspection that $\\boldsymbol{A}$ is not full rank, and is rank 2.\n",
    "\n",
    "Computing the SVD of $\\boldsymbol{A}$ and printing the singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(A)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two of the singular values are zero. To find a least-squares fit to the data with minimal $\\| \\boldsymbol{c}\\|_{2}$ we compute\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{c}} = \\boldsymbol{V}_{1} \\boldsymbol{\\Sigma}^{+} \n",
    "\\boldsymbol{U}_{1}^{T}\\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "Creating $\\boldsymbol{V}_{1}$,  $\\boldsymbol{\\Sigma}^{+}$ and $\\boldsymbol{U}_{1}$ (recall that the NumPy SVD returns $\\boldsymbol{V}^{T}$ rather than  $\\boldsymbol{V}$): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create view of U with last two columns removed \n",
    "U1 = U[:, :2]\n",
    "\n",
    "# Create view of V with last two columns removed \n",
    "V1 = V[:2,:]\n",
    "\n",
    "# Create Sigma^{+} by inverting the nonzero singular values and \n",
    "# discarding the zero singular values\n",
    "S1 = np.diag(1.0/s[:-2])\n",
    "print(S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the least-squares solution from $\\hat{\\boldsymbol{c}} = \\boldsymbol{V}_{1} \\boldsymbol{\\Sigma}^{+} \\boldsymbol{U}_{1}^{T}\\boldsymbol{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.transpose(V1).dot(S1.dot(U1.T).dot(f))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is $f(x, y) = 1 + 2x$, which in this case in fact interpolates the data points. Plotting the function, we have a plane that passes through the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot points\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$f$')\n",
    "ax.scatter(x, y, f)\n",
    "\n",
    "# Plot surface\n",
    "X = np.arange(0, 5, 0.2)\n",
    "Y = np.arange(-5, 5, 0.2)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = 1.0 + 2.0*X + 0.0*Y\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=5, cstride=5,  alpha=0.1)\n",
    "ax.view_init(elev=30, azim=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try adding some noise to the sample positions and the measured values. The Vandermonde matrix is no longer singular so we can solve $\\boldsymbol{A} \\boldsymbol{c} = \\boldsymbol{f}$ to get the polynomial coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "xn = x + 1.0e-3*(1.0 - np.random.rand(len(x)))\n",
    "yn = y + 1.0e-3*(1.0 - np.random.rand(len(y)))\n",
    "fn = f + 1.0e-3*(1.0 - np.random.rand(len(f)))\n",
    "\n",
    "A = np.polynomial.polynomial.polyvander2d(yn, xn, [1, 1])\n",
    "c = np.linalg.solve(A, fn)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see significant coefficients for the $y$ and $xy$ terms in the interpolating polynomial just as a consequence of adding small amount of noise. Plotting the surface and the points, we see in dramatic impact of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot points\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$f$')\n",
    "ax.scatter(xn, yn, fn)\n",
    "\n",
    "# Plot surface\n",
    "X = np.arange(0, 5, 0.2)\n",
    "Y = np.arange(-5, 5, 0.2)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = c[0] + c[1]*X + c[2]*Y + c[3]*X*Y\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=5, cstride=5,  alpha=0.1)\n",
    "ax.view_init(elev=30, azim=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing an SVD on the matrix with noise and printing the singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(A)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that two of the values are considerably small than the others. If we set these to zero and follow the least-squares procedure for rank-deficient problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create view of U with last two columns removed \n",
    "U1 = U[:, :2]\n",
    "\n",
    "# Create view of V with last two columns removed \n",
    "V1 = V[:2,:]\n",
    "\n",
    "# Create \\Sigma^{+}\n",
    "S1 = np.diag(1.0/s[:-2])\n",
    "\n",
    "c = np.transpose(V1).dot(S1.dot(U1.T).dot(f))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the fitting polynomial is very close to the noise-free case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis finds a transformation such that covariance of a data set is zero in the transformed directions, and the variance in these directions is greatest. From a dataset this tells us which are the 'important' parameters in a system.  \n",
    "\n",
    "Consider taking $N = 200$ measurements of two quantities $x_{1}$ and $x_{2}$. We model the system by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x0 = np.random.randn(200) + 5.0\n",
    "x1 = 1.5*x0 + np.random.rand(len(x0))\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.scatter(x0, x1, alpha=0.5);\n",
    "ax.set_xlabel('$x_{1}$');\n",
    "ax.set_ylabel('$x_{2}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect the data in a $200 \\times 2$ matrix $\\boldsymbol{X}$ (200 measurements, 2 variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((x0, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the covariance matrix $\\boldsymbol{C}$ by making the columns of $\\boldsymbol{X}$ zero mean and computing $\\boldsymbol{X}^{T}\\boldsymbol{X}^{T}/(N-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(X.shape[1]):\n",
    "    X[:,c] = X[:,c] - np.mean(X[:,c])\n",
    "C = (X.T).dot(X)/(len(x0)-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix is square and symmetric, so w can diagonalise it by computing the eigenvalues and eigenvectors.\n",
    "\n",
    "We could also compute the SVD of $\\boldsymbol{X}$ since the $\\boldsymbol{V}$ is made of the eigenvectors of $\\boldsymbol{X}^{T}\\boldsymbol{X}^{T}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(C)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data set and the principal directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.set_aspect(1.0);\n",
    "ax.set_ylim(-4.0, 4.0);\n",
    "ax.set_xlabel('$x_{1}$')\n",
    "ax.set_ylabel('$x_{2}$')\n",
    "ax.quiver(V[0, 0], V[0, 1], angles='xy',scale_units='xy',scale=0.3);\n",
    "ax.quiver(V[1, 0], V[1, 1], angles='xy',scale_units='xy',scale=1);\n",
    "ax.scatter(X[:,0], X[:,1], alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA effectively detects correlation in a data set. In the above example it suggest that the system could be modelled with one variable in the direction of the first column of $\\boldsymbol{V}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "widgets": {
   "state": {
    "fa7e7d0256b749aba4ed07f89f8268c5": {
     "views": [
      {
       "cell_index": 64
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
